-----------------------
* Threads and Locking *
-----------------------

The A1 library has been designed to be thread safe, when helper thread or interrupts are enabled or when the user has specified a 
A1_THREAD_MULTIPLE as the thread level. A global (DCMF) lock is acquired on entry into any of any A1D function. 
The lock is given up of exit of the function or when waiting on communication progress, thus allowing the helper 
thread (CHT) to acquire the lock and hit advance (DCMF_Messager_advance). When the helper thread is not present, 
the lock is retained and the main thread hits advance until the required communication progress is achieved.

None of the A1DI functions should acquire the lock since these functions are called from within the A1D functions or from inside 
a DCMF Callback at which point the lock would have already been acquired. 

------------------------------------------
* CHT, Interrupts and DCMF Thread levels *
------------------------------------------

When CHT is enabled, we use our own global lock using BGP Atomics. So, we configure DCMF in THREAD_SERIALIZED mode as only one 
thread will be making a DCMF call at any point of time. 

Initially, I had implemented a test-and-set lock using the BGP Atomics but this appeared to be causing a lot of contention. On Jeff's 
suggestion I replaced this with test-test-and-set lock and this seems to be a perfect fit with almost zero contention.
However, this scheme has an issue when there in no CHT delay (the time for which CHT waits between lock cycles). The main 
thread never gets the lock leading to starvation. Introducing a CHT delay of around 70 cycles solves this (default is set to 200 
on the conservative side). One has to keep in mind that this delay required can change from system to system. This parameter 
can be modified using a run-time parameter, A1_CHT_PAUSE_CYCLES.

--------------------------------
* Request pool and Handle pool *
--------------------------------

I have implemented DCMF request pool and A1 handle pool separately as a single handle can have multiple requests 
associated with it (aggregate requests and non-contiguous direct operations). Both the pools are implemented as 
singly linked lists. They are popped off the head in 
the Get_handle and Get_request functions and are tracked using callbacks. They are returned to the pool once the 
local callback in complete. The issued requests/handles are not tracked in any other way. This places a restriction of 
requiring a local callback on every DCMF operation posted (one exception is non-contiguous direct operations where 
a callback on the last operation will suffice). When the request/handle pools are dry, A1 waits on advance until there 
is a free request/handle available. 

TODO list 

done - Introduce API and functions to initialize handle (Application should initialize A1 handles before using 
  them)
done - Use enable_cht as the option name for CHT
done - Modify locking macros to switch between Bgp_Atomics for CHT (THREAD_SINGLE) and DCMF_CS for Interrupts. 
- Evaluate lock contention using bgp_atomics and see if contention varies with the processor assginment for
  CHT
- Verify functionality of Non-blocking operations and evaluate bandwidth performance.
- Make cht/interrupts a configure time option. 
- Implement shared counters using atomics.
- Optimize accumulate operations using all the floating point registers in double hummer (Kaz' suggestion)
- Add logic for a scale-free flush design.
- Implement Vector operations - over simple Put/Get/Accumulate 
- Implement AllReduce and Reduce using DCMF collectives
